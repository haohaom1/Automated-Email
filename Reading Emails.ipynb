{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imaplib\n",
    "import email\n",
    "import quopri\n",
    "import re\n",
    "import html\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'prospectstudent@colby.edu'\n",
    "password = 'Student.2017'\n",
    "\n",
    "# username = 'haohaom2@gmail.com'\n",
    "# password = '62947394'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the email INBOX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('OK', [b'893'])"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mail = imaplib.IMAP4_SSL('imap.gmail.com')\n",
    "mail.login(username, password)\n",
    "mail.list()\n",
    "# Out: list of \"folders\" aka labels in gmail.\n",
    "# mail.select(\"inbox\") # connect to inbox.\n",
    "mail.select('\"Google Alerts/Completed\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, data = mail.uid('search', None, \"ALL\") # search and return uids instead\n",
    "\n",
    "first_email_uid = data[0].split()[0]\n",
    "latest_email_uid = data[0].split()[-1]\n",
    "\n",
    "test_email_uid = data[0].split()[-22]\n",
    "\n",
    "ids = data[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('first email uid ', first_email_id)\n",
    "# print('latest_email_uid ', latest_email_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the email message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Alert - \"Phillip Frost\"\n"
     ]
    }
   ],
   "source": [
    "result, data = mail.uid('fetch', test_email_uid, '(RFC822)')\n",
    "raw_email = str(data[0][1], 'utf-8')\n",
    "email_message = email.message_from_string(raw_email)\n",
    "print(email_message['subject'])\n",
    "subject = email_message['subject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_email(email_msg):\n",
    "    if email_msg.is_multipart():\n",
    "        s = ''\n",
    "        for payload in email_msg.get_payload():\n",
    "            s += payload.get_payload()\n",
    "    else:\n",
    "        s = b.get_payload()\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This cleans html stuff so I can extract the xml code\n",
    "text = get_text_from_email(email_message).replace('\\r\\n', '').replace('=', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts xml files from the raw string text\n",
    "def extract_xml(raw_text):\n",
    "    raw_text = raw_text.replace('\\r\\n', '').replace('=', '')\n",
    "    m = re.findall('alerts/feeds\\S+', raw_text)\n",
    "    \n",
    "    links = [('https://www.google.com/' + x).replace('\\\"', '') for x in m]\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Regex to get the links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passes in an xml link\n",
    "# returns a list of links used in the website\n",
    "def get_url_from_xml(xml_link):\n",
    "    r  = requests.get(xml_link)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')   # creates a BS4 from given xml link\n",
    "    web_lists = soup.find_all('link')[1:]            # finds all the BS4 links\n",
    "    \n",
    "    urls = [re.findall('url=(.*?)&', url['href'])[0] for url in web_lists]\n",
    "    \n",
    "    if not urls:\n",
    "        return re.findall('(?<=url3D)(.*?)(?=\\\\\\\\u0026)', text)\n",
    "    \n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.miamitodaynews.com/event/outsider-artists-from-havana/',\n",
       " 'https://www.gurufocus.com/news/679424/2-stocks-move-wednesday',\n",
       " 'https://investingnews.com/daily/life-science-investing/genetics-investing/opko-health-reports-first-quarter-2018-financial-results/']"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = get_url_from_xml(extract_xml(text)[0])\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.gurufocus.com/news/679424/2-stocks-move-wednesday'"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = get_url_from_xml(extract_xml(text)[0])[0]\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re.findall('(?<=url3D)(.*?)(?=\\\\\\\\u0026)', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapes each link and creates a keyward card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "r  = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(r.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "This page was added to your Bookmark.\n",
      "\n",
      "Members Only. Please Sign Up or Log In first.\n",
      "\n",
      "Bookmark of this page has been deleted.\n",
      "\n",
      "Shares of OPKO Health Inc. (NASDAQ:OPK) jumped on Wednesday after the company reported a loss of 8 cents in the first quarter on revenue of $254.9 million, down 4.3% year over year. The company managed to beat earnings estimates by 5 cents and revenue expectations by $18 million.\n",
      "“We are pleased to report steady sequential-quarter growth for RAYALDEE and 4Kscore, as well as improvement in our lab business from Q4 of last year,” Chairman and CEO Phillip Frost said. “The improved first quarter results were in line with our expectations, starting 2018 positively coming off challenging fourth quarter 2017 results. These factors, taken together, reflect progress across the breadth of our commercial and laboratory services.”\n",
      "\n",
      "On the other hand, MaxLinear Inc. (NYSE:MXL) fell after reporting financial results for the first quarter. Earnings per share of 37 cents beat estimates by one cent, but revenue of $110.8 million fell $1.09 million short of expectations. The company realized strong GAAP and non-GAAP gross margins of 56.5% and 64.9%, and GAAP and non-GAAP income from operations of 4% and 29%.\n",
      "Looking ahead, the company expects second-quarter revenue in the range of $100 million to $110 million.\n",
      "Disclosure: The author holds no positions in any stocks mentioned.\n",
      "Rating:  0.0/5 (0 votes) \n",
      "Select portfolio(s):\n",
      "Why you are interested?\n",
      "\n",
      "Your selection and notes will be stored in your portfolio.\n",
      "\n",
      "\n",
      "Disclaimers: GuruFocus.com is not operated by a broker, a dealer, or a registered investment adviser. Under no circumstances does any information posted on GuruFocus.com represent a recommendation to buy or sell a security. The information on this site, and in its related newsletters, is not intended to be, nor does it constitute, investment advice or recommendations. The gurus may buy and sell securities before and after any particular article and report and information herein is published, with respect to the securities discussed in any article and report posted herein. In no event shall GuruFocus.com be liable to any member, guest or third party for any damages of any kind arising out of the use of any content or other material published or available on GuruFocus.com, or relating to the use of, or inability to use, GuruFocus.com or any content, including, without limitation, any investment losses, lost profits, lost opportunity, special, incidental, indirect, consequential or punitive damages. Past performance is a poor indicator of future performance. The information on this site, and in its related newsletters, is not intended to be, nor does it constitute, investment advice or recommendations. The information on this site is in no way guaranteed for completeness, accuracy or in any other way. The gurus listed in this website are not affiliated with GuruFocus.com, LLC.\n",
      "Stock quotes provided by InterActive Data. Fundamental company data provided by Morningstar, updated daily.\n",
      "GF Chat\n"
     ]
    }
   ],
   "source": [
    "for paragraph in soup.find_all('p'):\n",
    "    print(paragraph.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['This', 'page', 'was', 'added', 'to', 'your', 'Bookmark.'],\n",
       " ['Members', 'Only.', 'Please', 'Sign', 'Up', 'or', 'Log', 'In', 'first.'],\n",
       " ['Bookmark', 'of', 'this', 'page', 'has', 'been', 'deleted.'],\n",
       " ['Shares',\n",
       "  'of',\n",
       "  'OPKO',\n",
       "  'Health',\n",
       "  'Inc.',\n",
       "  '(NASDAQ:OPK)',\n",
       "  'jumped',\n",
       "  'on',\n",
       "  'Wednesday',\n",
       "  'after',\n",
       "  'the',\n",
       "  'company',\n",
       "  'reported',\n",
       "  'a',\n",
       "  'loss',\n",
       "  'of',\n",
       "  '8',\n",
       "  'cents',\n",
       "  'in',\n",
       "  'the',\n",
       "  'first',\n",
       "  'quarter',\n",
       "  'on',\n",
       "  'revenue',\n",
       "  'of',\n",
       "  '$254.9',\n",
       "  'million,',\n",
       "  'down',\n",
       "  '4.3%',\n",
       "  'year',\n",
       "  'over',\n",
       "  'year.',\n",
       "  'The',\n",
       "  'company',\n",
       "  'managed',\n",
       "  'to',\n",
       "  'beat',\n",
       "  'earnings',\n",
       "  'estimates',\n",
       "  'by',\n",
       "  '5',\n",
       "  'cents',\n",
       "  'and',\n",
       "  'revenue',\n",
       "  'expectations',\n",
       "  'by',\n",
       "  '$18',\n",
       "  'million.'],\n",
       " ['“We',\n",
       "  'are',\n",
       "  'pleased',\n",
       "  'to',\n",
       "  'report',\n",
       "  'steady',\n",
       "  'sequential-quarter',\n",
       "  'growth',\n",
       "  'for',\n",
       "  'RAYALDEE',\n",
       "  'and',\n",
       "  '4Kscore,',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'improvement',\n",
       "  'in',\n",
       "  'our',\n",
       "  'lab',\n",
       "  'business',\n",
       "  'from',\n",
       "  'Q4',\n",
       "  'of',\n",
       "  'last',\n",
       "  'year,”',\n",
       "  'Chairman',\n",
       "  'and',\n",
       "  'CEO',\n",
       "  'Phillip',\n",
       "  'Frost',\n",
       "  'said.',\n",
       "  '“The',\n",
       "  'improved',\n",
       "  'first',\n",
       "  'quarter',\n",
       "  'results',\n",
       "  'were',\n",
       "  'in',\n",
       "  'line',\n",
       "  'with',\n",
       "  'our',\n",
       "  'expectations,',\n",
       "  'starting',\n",
       "  '2018',\n",
       "  'positively',\n",
       "  'coming',\n",
       "  'off',\n",
       "  'challenging',\n",
       "  'fourth',\n",
       "  'quarter',\n",
       "  '2017',\n",
       "  'results.',\n",
       "  'These',\n",
       "  'factors,',\n",
       "  'taken',\n",
       "  'together,',\n",
       "  'reflect',\n",
       "  'progress',\n",
       "  'across',\n",
       "  'the',\n",
       "  'breadth',\n",
       "  'of',\n",
       "  'our',\n",
       "  'commercial',\n",
       "  'and',\n",
       "  'laboratory',\n",
       "  'services.”'],\n",
       " [],\n",
       " ['On',\n",
       "  'the',\n",
       "  'other',\n",
       "  'hand,',\n",
       "  'MaxLinear',\n",
       "  'Inc.',\n",
       "  '(NYSE:MXL)',\n",
       "  'fell',\n",
       "  'after',\n",
       "  'reporting',\n",
       "  'financial',\n",
       "  'results',\n",
       "  'for',\n",
       "  'the',\n",
       "  'first',\n",
       "  'quarter.',\n",
       "  'Earnings',\n",
       "  'per',\n",
       "  'share',\n",
       "  'of',\n",
       "  '37',\n",
       "  'cents',\n",
       "  'beat',\n",
       "  'estimates',\n",
       "  'by',\n",
       "  'one',\n",
       "  'cent,',\n",
       "  'but',\n",
       "  'revenue',\n",
       "  'of',\n",
       "  '$110.8',\n",
       "  'million',\n",
       "  'fell',\n",
       "  '$1.09',\n",
       "  'million',\n",
       "  'short',\n",
       "  'of',\n",
       "  'expectations.',\n",
       "  'The',\n",
       "  'company',\n",
       "  'realized',\n",
       "  'strong',\n",
       "  'GAAP',\n",
       "  'and',\n",
       "  'non-GAAP',\n",
       "  'gross',\n",
       "  'margins',\n",
       "  'of',\n",
       "  '56.5%',\n",
       "  'and',\n",
       "  '64.9%,',\n",
       "  'and',\n",
       "  'GAAP',\n",
       "  'and',\n",
       "  'non-GAAP',\n",
       "  'income',\n",
       "  'from',\n",
       "  'operations',\n",
       "  'of',\n",
       "  '4%',\n",
       "  'and',\n",
       "  '29%.'],\n",
       " ['Looking',\n",
       "  'ahead,',\n",
       "  'the',\n",
       "  'company',\n",
       "  'expects',\n",
       "  'second-quarter',\n",
       "  'revenue',\n",
       "  'in',\n",
       "  'the',\n",
       "  'range',\n",
       "  'of',\n",
       "  '$100',\n",
       "  'million',\n",
       "  'to',\n",
       "  '$110',\n",
       "  'million.'],\n",
       " ['Disclosure:',\n",
       "  'The',\n",
       "  'author',\n",
       "  'holds',\n",
       "  'no',\n",
       "  'positions',\n",
       "  'in',\n",
       "  'any',\n",
       "  'stocks',\n",
       "  'mentioned.'],\n",
       " ['Rating:', '0.0/5', '(0', 'votes)'],\n",
       " ['Select', 'portfolio(s):'],\n",
       " ['Why', 'you', 'are', 'interested?'],\n",
       " ['Your',\n",
       "  'selection',\n",
       "  'and',\n",
       "  'notes',\n",
       "  'will',\n",
       "  'be',\n",
       "  'stored',\n",
       "  'in',\n",
       "  'your',\n",
       "  'portfolio.'],\n",
       " ['Disclaimers:',\n",
       "  'GuruFocus.com',\n",
       "  'is',\n",
       "  'not',\n",
       "  'operated',\n",
       "  'by',\n",
       "  'a',\n",
       "  'broker,',\n",
       "  'a',\n",
       "  'dealer,',\n",
       "  'or',\n",
       "  'a',\n",
       "  'registered',\n",
       "  'investment',\n",
       "  'adviser.',\n",
       "  'Under',\n",
       "  'no',\n",
       "  'circumstances',\n",
       "  'does',\n",
       "  'any',\n",
       "  'information',\n",
       "  'posted',\n",
       "  'on',\n",
       "  'GuruFocus.com',\n",
       "  'represent',\n",
       "  'a',\n",
       "  'recommendation',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'or',\n",
       "  'sell',\n",
       "  'a',\n",
       "  'security.',\n",
       "  'The',\n",
       "  'information',\n",
       "  'on',\n",
       "  'this',\n",
       "  'site,',\n",
       "  'and',\n",
       "  'in',\n",
       "  'its',\n",
       "  'related',\n",
       "  'newsletters,',\n",
       "  'is',\n",
       "  'not',\n",
       "  'intended',\n",
       "  'to',\n",
       "  'be,',\n",
       "  'nor',\n",
       "  'does',\n",
       "  'it',\n",
       "  'constitute,',\n",
       "  'investment',\n",
       "  'advice',\n",
       "  'or',\n",
       "  'recommendations.',\n",
       "  'The',\n",
       "  'gurus',\n",
       "  'may',\n",
       "  'buy',\n",
       "  'and',\n",
       "  'sell',\n",
       "  'securities',\n",
       "  'before',\n",
       "  'and',\n",
       "  'after',\n",
       "  'any',\n",
       "  'particular',\n",
       "  'article',\n",
       "  'and',\n",
       "  'report',\n",
       "  'and',\n",
       "  'information',\n",
       "  'herein',\n",
       "  'is',\n",
       "  'published,',\n",
       "  'with',\n",
       "  'respect',\n",
       "  'to',\n",
       "  'the',\n",
       "  'securities',\n",
       "  'discussed',\n",
       "  'in',\n",
       "  'any',\n",
       "  'article',\n",
       "  'and',\n",
       "  'report',\n",
       "  'posted',\n",
       "  'herein.',\n",
       "  'In',\n",
       "  'no',\n",
       "  'event',\n",
       "  'shall',\n",
       "  'GuruFocus.com',\n",
       "  'be',\n",
       "  'liable',\n",
       "  'to',\n",
       "  'any',\n",
       "  'member,',\n",
       "  'guest',\n",
       "  'or',\n",
       "  'third',\n",
       "  'party',\n",
       "  'for',\n",
       "  'any',\n",
       "  'damages',\n",
       "  'of',\n",
       "  'any',\n",
       "  'kind',\n",
       "  'arising',\n",
       "  'out',\n",
       "  'of',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of',\n",
       "  'any',\n",
       "  'content',\n",
       "  'or',\n",
       "  'other',\n",
       "  'material',\n",
       "  'published',\n",
       "  'or',\n",
       "  'available',\n",
       "  'on',\n",
       "  'GuruFocus.com,',\n",
       "  'or',\n",
       "  'relating',\n",
       "  'to',\n",
       "  'the',\n",
       "  'use',\n",
       "  'of,',\n",
       "  'or',\n",
       "  'inability',\n",
       "  'to',\n",
       "  'use,',\n",
       "  'GuruFocus.com',\n",
       "  'or',\n",
       "  'any',\n",
       "  'content,',\n",
       "  'including,',\n",
       "  'without',\n",
       "  'limitation,',\n",
       "  'any',\n",
       "  'investment',\n",
       "  'losses,',\n",
       "  'lost',\n",
       "  'profits,',\n",
       "  'lost',\n",
       "  'opportunity,',\n",
       "  'special,',\n",
       "  'incidental,',\n",
       "  'indirect,',\n",
       "  'consequential',\n",
       "  'or',\n",
       "  'punitive',\n",
       "  'damages.',\n",
       "  'Past',\n",
       "  'performance',\n",
       "  'is',\n",
       "  'a',\n",
       "  'poor',\n",
       "  'indicator',\n",
       "  'of',\n",
       "  'future',\n",
       "  'performance.',\n",
       "  'The',\n",
       "  'information',\n",
       "  'on',\n",
       "  'this',\n",
       "  'site,',\n",
       "  'and',\n",
       "  'in',\n",
       "  'its',\n",
       "  'related',\n",
       "  'newsletters,',\n",
       "  'is',\n",
       "  'not',\n",
       "  'intended',\n",
       "  'to',\n",
       "  'be,',\n",
       "  'nor',\n",
       "  'does',\n",
       "  'it',\n",
       "  'constitute,',\n",
       "  'investment',\n",
       "  'advice',\n",
       "  'or',\n",
       "  'recommendations.',\n",
       "  'The',\n",
       "  'information',\n",
       "  'on',\n",
       "  'this',\n",
       "  'site',\n",
       "  'is',\n",
       "  'in',\n",
       "  'no',\n",
       "  'way',\n",
       "  'guaranteed',\n",
       "  'for',\n",
       "  'completeness,',\n",
       "  'accuracy',\n",
       "  'or',\n",
       "  'in',\n",
       "  'any',\n",
       "  'other',\n",
       "  'way.',\n",
       "  'The',\n",
       "  'gurus',\n",
       "  'listed',\n",
       "  'in',\n",
       "  'this',\n",
       "  'website',\n",
       "  'are',\n",
       "  'not',\n",
       "  'affiliated',\n",
       "  'with',\n",
       "  'GuruFocus.com,',\n",
       "  'LLC.',\n",
       "  'Stock',\n",
       "  'quotes',\n",
       "  'provided',\n",
       "  'by',\n",
       "  'InterActive',\n",
       "  'Data.',\n",
       "  'Fundamental',\n",
       "  'company',\n",
       "  'data',\n",
       "  'provided',\n",
       "  'by',\n",
       "  'Morningstar,',\n",
       "  'updated',\n",
       "  'daily.'],\n",
       " ['GF', 'Chat']]"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[paragraph.text.split() for paragraph in soup.find_all('p')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean text of punctuations and store them all in a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for paragraph in soup.find_all('p'):\n",
    "    words += paragraph.text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'page',\n",
       " 'was',\n",
       " 'added',\n",
       " 'to',\n",
       " 'your',\n",
       " 'Bookmark.',\n",
       " 'Members',\n",
       " 'Only.',\n",
       " 'Please',\n",
       " 'Sign',\n",
       " 'Up',\n",
       " 'or',\n",
       " 'Log',\n",
       " 'In',\n",
       " 'first.',\n",
       " 'Bookmark',\n",
       " 'of',\n",
       " 'this',\n",
       " 'page',\n",
       " 'has',\n",
       " 'been',\n",
       " 'deleted.',\n",
       " 'Shares',\n",
       " 'of',\n",
       " 'OPKO',\n",
       " 'Health',\n",
       " 'Inc.',\n",
       " '(NASDAQ:OPK)',\n",
       " 'jumped',\n",
       " 'on',\n",
       " 'Wednesday',\n",
       " 'after',\n",
       " 'the',\n",
       " 'company',\n",
       " 'reported',\n",
       " 'a',\n",
       " 'loss',\n",
       " 'of',\n",
       " '8',\n",
       " 'cents',\n",
       " 'in',\n",
       " 'the',\n",
       " 'first',\n",
       " 'quarter',\n",
       " 'on',\n",
       " 'revenue',\n",
       " 'of',\n",
       " '$254.9',\n",
       " 'million,',\n",
       " 'down',\n",
       " '4.3%',\n",
       " 'year',\n",
       " 'over',\n",
       " 'year.',\n",
       " 'The',\n",
       " 'company',\n",
       " 'managed',\n",
       " 'to',\n",
       " 'beat',\n",
       " 'earnings',\n",
       " 'estimates',\n",
       " 'by',\n",
       " '5',\n",
       " 'cents',\n",
       " 'and',\n",
       " 'revenue',\n",
       " 'expectations',\n",
       " 'by',\n",
       " '$18',\n",
       " 'million.',\n",
       " '“We',\n",
       " 'are',\n",
       " 'pleased',\n",
       " 'to',\n",
       " 'report',\n",
       " 'steady',\n",
       " 'sequential-quarter',\n",
       " 'growth',\n",
       " 'for',\n",
       " 'RAYALDEE',\n",
       " 'and',\n",
       " '4Kscore,',\n",
       " 'as',\n",
       " 'well',\n",
       " 'as',\n",
       " 'improvement',\n",
       " 'in',\n",
       " 'our',\n",
       " 'lab',\n",
       " 'business',\n",
       " 'from',\n",
       " 'Q4',\n",
       " 'of',\n",
       " 'last',\n",
       " 'year,”',\n",
       " 'Chairman',\n",
       " 'and',\n",
       " 'CEO',\n",
       " 'Phillip',\n",
       " 'Frost',\n",
       " 'said.',\n",
       " '“The',\n",
       " 'improved',\n",
       " 'first',\n",
       " 'quarter',\n",
       " 'results',\n",
       " 'were',\n",
       " 'in',\n",
       " 'line',\n",
       " 'with',\n",
       " 'our',\n",
       " 'expectations,',\n",
       " 'starting',\n",
       " '2018',\n",
       " 'positively',\n",
       " 'coming',\n",
       " 'off',\n",
       " 'challenging',\n",
       " 'fourth',\n",
       " 'quarter',\n",
       " '2017',\n",
       " 'results.',\n",
       " 'These',\n",
       " 'factors,',\n",
       " 'taken',\n",
       " 'together,',\n",
       " 'reflect',\n",
       " 'progress',\n",
       " 'across',\n",
       " 'the',\n",
       " 'breadth',\n",
       " 'of',\n",
       " 'our',\n",
       " 'commercial',\n",
       " 'and',\n",
       " 'laboratory',\n",
       " 'services.”',\n",
       " 'On',\n",
       " 'the',\n",
       " 'other',\n",
       " 'hand,',\n",
       " 'MaxLinear',\n",
       " 'Inc.',\n",
       " '(NYSE:MXL)',\n",
       " 'fell',\n",
       " 'after',\n",
       " 'reporting',\n",
       " 'financial',\n",
       " 'results',\n",
       " 'for',\n",
       " 'the',\n",
       " 'first',\n",
       " 'quarter.',\n",
       " 'Earnings',\n",
       " 'per',\n",
       " 'share',\n",
       " 'of',\n",
       " '37',\n",
       " 'cents',\n",
       " 'beat',\n",
       " 'estimates',\n",
       " 'by',\n",
       " 'one',\n",
       " 'cent,',\n",
       " 'but',\n",
       " 'revenue',\n",
       " 'of',\n",
       " '$110.8',\n",
       " 'million',\n",
       " 'fell',\n",
       " '$1.09',\n",
       " 'million',\n",
       " 'short',\n",
       " 'of',\n",
       " 'expectations.',\n",
       " 'The',\n",
       " 'company',\n",
       " 'realized',\n",
       " 'strong',\n",
       " 'GAAP',\n",
       " 'and',\n",
       " 'non-GAAP',\n",
       " 'gross',\n",
       " 'margins',\n",
       " 'of',\n",
       " '56.5%',\n",
       " 'and',\n",
       " '64.9%,',\n",
       " 'and',\n",
       " 'GAAP',\n",
       " 'and',\n",
       " 'non-GAAP',\n",
       " 'income',\n",
       " 'from',\n",
       " 'operations',\n",
       " 'of',\n",
       " '4%',\n",
       " 'and',\n",
       " '29%.',\n",
       " 'Looking',\n",
       " 'ahead,',\n",
       " 'the',\n",
       " 'company',\n",
       " 'expects',\n",
       " 'second-quarter',\n",
       " 'revenue',\n",
       " 'in',\n",
       " 'the',\n",
       " 'range',\n",
       " 'of',\n",
       " '$100',\n",
       " 'million',\n",
       " 'to',\n",
       " '$110',\n",
       " 'million.',\n",
       " 'Disclosure:',\n",
       " 'The',\n",
       " 'author',\n",
       " 'holds',\n",
       " 'no',\n",
       " 'positions',\n",
       " 'in',\n",
       " 'any',\n",
       " 'stocks',\n",
       " 'mentioned.',\n",
       " 'Rating:',\n",
       " '0.0/5',\n",
       " '(0',\n",
       " 'votes)',\n",
       " 'Select',\n",
       " 'portfolio(s):',\n",
       " 'Why',\n",
       " 'you',\n",
       " 'are',\n",
       " 'interested?',\n",
       " 'Your',\n",
       " 'selection',\n",
       " 'and',\n",
       " 'notes',\n",
       " 'will',\n",
       " 'be',\n",
       " 'stored',\n",
       " 'in',\n",
       " 'your',\n",
       " 'portfolio.',\n",
       " 'Disclaimers:',\n",
       " 'GuruFocus.com',\n",
       " 'is',\n",
       " 'not',\n",
       " 'operated',\n",
       " 'by',\n",
       " 'a',\n",
       " 'broker,',\n",
       " 'a',\n",
       " 'dealer,',\n",
       " 'or',\n",
       " 'a',\n",
       " 'registered',\n",
       " 'investment',\n",
       " 'adviser.',\n",
       " 'Under',\n",
       " 'no',\n",
       " 'circumstances',\n",
       " 'does',\n",
       " 'any',\n",
       " 'information',\n",
       " 'posted',\n",
       " 'on',\n",
       " 'GuruFocus.com',\n",
       " 'represent',\n",
       " 'a',\n",
       " 'recommendation',\n",
       " 'to',\n",
       " 'buy',\n",
       " 'or',\n",
       " 'sell',\n",
       " 'a',\n",
       " 'security.',\n",
       " 'The',\n",
       " 'information',\n",
       " 'on',\n",
       " 'this',\n",
       " 'site,',\n",
       " 'and',\n",
       " 'in',\n",
       " 'its',\n",
       " 'related',\n",
       " 'newsletters,',\n",
       " 'is',\n",
       " 'not',\n",
       " 'intended',\n",
       " 'to',\n",
       " 'be,',\n",
       " 'nor',\n",
       " 'does',\n",
       " 'it',\n",
       " 'constitute,',\n",
       " 'investment',\n",
       " 'advice',\n",
       " 'or',\n",
       " 'recommendations.',\n",
       " 'The',\n",
       " 'gurus',\n",
       " 'may',\n",
       " 'buy',\n",
       " 'and',\n",
       " 'sell',\n",
       " 'securities',\n",
       " 'before',\n",
       " 'and',\n",
       " 'after',\n",
       " 'any',\n",
       " 'particular',\n",
       " 'article',\n",
       " 'and',\n",
       " 'report',\n",
       " 'and',\n",
       " 'information',\n",
       " 'herein',\n",
       " 'is',\n",
       " 'published,',\n",
       " 'with',\n",
       " 'respect',\n",
       " 'to',\n",
       " 'the',\n",
       " 'securities',\n",
       " 'discussed',\n",
       " 'in',\n",
       " 'any',\n",
       " 'article',\n",
       " 'and',\n",
       " 'report',\n",
       " 'posted',\n",
       " 'herein.',\n",
       " 'In',\n",
       " 'no',\n",
       " 'event',\n",
       " 'shall',\n",
       " 'GuruFocus.com',\n",
       " 'be',\n",
       " 'liable',\n",
       " 'to',\n",
       " 'any',\n",
       " 'member,',\n",
       " 'guest',\n",
       " 'or',\n",
       " 'third',\n",
       " 'party',\n",
       " 'for',\n",
       " 'any',\n",
       " 'damages',\n",
       " 'of',\n",
       " 'any',\n",
       " 'kind',\n",
       " 'arising',\n",
       " 'out',\n",
       " 'of',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of',\n",
       " 'any',\n",
       " 'content',\n",
       " 'or',\n",
       " 'other',\n",
       " 'material',\n",
       " 'published',\n",
       " 'or',\n",
       " 'available',\n",
       " 'on',\n",
       " 'GuruFocus.com,',\n",
       " 'or',\n",
       " 'relating',\n",
       " 'to',\n",
       " 'the',\n",
       " 'use',\n",
       " 'of,',\n",
       " 'or',\n",
       " 'inability',\n",
       " 'to',\n",
       " 'use,',\n",
       " 'GuruFocus.com',\n",
       " 'or',\n",
       " 'any',\n",
       " 'content,',\n",
       " 'including,',\n",
       " 'without',\n",
       " 'limitation,',\n",
       " 'any',\n",
       " 'investment',\n",
       " 'losses,',\n",
       " 'lost',\n",
       " 'profits,',\n",
       " 'lost',\n",
       " 'opportunity,',\n",
       " 'special,',\n",
       " 'incidental,',\n",
       " 'indirect,',\n",
       " 'consequential',\n",
       " 'or',\n",
       " 'punitive',\n",
       " 'damages.',\n",
       " 'Past',\n",
       " 'performance',\n",
       " 'is',\n",
       " 'a',\n",
       " 'poor',\n",
       " 'indicator',\n",
       " 'of',\n",
       " 'future',\n",
       " 'performance.',\n",
       " 'The',\n",
       " 'information',\n",
       " 'on',\n",
       " 'this',\n",
       " 'site,',\n",
       " 'and',\n",
       " 'in',\n",
       " 'its',\n",
       " 'related',\n",
       " 'newsletters,',\n",
       " 'is',\n",
       " 'not',\n",
       " 'intended',\n",
       " 'to',\n",
       " 'be,',\n",
       " 'nor',\n",
       " 'does',\n",
       " 'it',\n",
       " 'constitute,',\n",
       " 'investment',\n",
       " 'advice',\n",
       " 'or',\n",
       " 'recommendations.',\n",
       " 'The',\n",
       " 'information',\n",
       " 'on',\n",
       " 'this',\n",
       " 'site',\n",
       " 'is',\n",
       " 'in',\n",
       " 'no',\n",
       " 'way',\n",
       " 'guaranteed',\n",
       " 'for',\n",
       " 'completeness,',\n",
       " 'accuracy',\n",
       " 'or',\n",
       " 'in',\n",
       " 'any',\n",
       " 'other',\n",
       " 'way.',\n",
       " 'The',\n",
       " 'gurus',\n",
       " 'listed',\n",
       " 'in',\n",
       " 'this',\n",
       " 'website',\n",
       " 'are',\n",
       " 'not',\n",
       " 'affiliated',\n",
       " 'with',\n",
       " 'GuruFocus.com,',\n",
       " 'LLC.',\n",
       " 'Stock',\n",
       " 'quotes',\n",
       " 'provided',\n",
       " 'by',\n",
       " 'InterActive',\n",
       " 'Data.',\n",
       " 'Fundamental',\n",
       " 'company',\n",
       " 'data',\n",
       " 'provided',\n",
       " 'by',\n",
       " 'Morningstar,',\n",
       " 'updated',\n",
       " 'daily.',\n",
       " 'GF',\n",
       " 'Chat']"
      ]
     },
     "execution_count": 627,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Saves words as a list of all the words that appear\n",
    "import string\n",
    "words = list(map(lambda x: x.strip(string.punctuation), words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creates a set of the top 100 most common words, which will be filtered out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = pd.read_table('google-10000-english-no-swears.txt', names=['words'], nrows=100)\n",
    "common_words = set(common_words['words'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve Subject information from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = re.findall('\"(.*?)\"', subject)[0]\n",
    "fname, lname = name.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bioConsId</th>\n",
       "      <th>bioFirstName</th>\n",
       "      <th>bioLastName</th>\n",
       "      <th>bioEmplPosition</th>\n",
       "      <th>bioEmplName</th>\n",
       "      <th>bioPrefAddrCity</th>\n",
       "      <th>bioPrefAddrState</th>\n",
       "      <th>bioSpId</th>\n",
       "      <th>Bday</th>\n",
       "      <th>MidName</th>\n",
       "      <th>NickName</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002709</td>\n",
       "      <td>Christopher</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>Founder</td>\n",
       "      <td>botanica</td>\n",
       "      <td>Bainbridge Island</td>\n",
       "      <td>WA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12/28/1970</td>\n",
       "      <td>C.</td>\n",
       "      <td>Chris</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1004278</td>\n",
       "      <td>Barbara</td>\n",
       "      <td>Brackett</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Asheville</td>\n",
       "      <td>NC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1004328</td>\n",
       "      <td>Marie</td>\n",
       "      <td>Juzova</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1/13/1908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004427</td>\n",
       "      <td>Donald</td>\n",
       "      <td>Emack</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5/9/1908</td>\n",
       "      <td>A.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1004496</td>\n",
       "      <td>Francis</td>\n",
       "      <td>Smith</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Naples</td>\n",
       "      <td>FL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3/3/1908</td>\n",
       "      <td>B.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bioConsId bioFirstName bioLastName bioEmplPosition bioEmplName  \\\n",
       "1    1002709  Christopher      Abbott         Founder    botanica   \n",
       "2    1004278      Barbara    Brackett             NaN         NaN   \n",
       "3    1004328        Marie      Juzova             NaN         NaN   \n",
       "4    1004427       Donald       Emack             NaN         NaN   \n",
       "5    1004496      Francis       Smith             NaN         NaN   \n",
       "\n",
       "     bioPrefAddrCity bioPrefAddrState  bioSpId        Bday MidName NickName  \\\n",
       "1  Bainbridge Island               WA      NaN  12/28/1970      C.    Chris   \n",
       "2          Asheville               NC      NaN         NaN      M.      NaN   \n",
       "3                NaN              NaN      NaN   1/13/1908     NaN      NaN   \n",
       "4                NaN              NaN      NaN    5/9/1908      A.      NaN   \n",
       "5             Naples               FL      NaN    3/3/1908      B.      NaN   \n",
       "\n",
       "     age  \n",
       "1   47.0  \n",
       "2    NaN  \n",
       "3  110.0  \n",
       "4  109.0  \n",
       "5  110.0  "
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### CHANGE PATH FOR LOCATION OF THE DATASET\n",
    "path = r'\\Users\\xfu21\\Desktop\\\\'\n",
    "file = path + 'constituents_data.csv'\n",
    "\n",
    "df = pd.read_csv(file, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bioConsId</th>\n",
       "      <th>bioFirstName</th>\n",
       "      <th>bioLastName</th>\n",
       "      <th>bioEmplPosition</th>\n",
       "      <th>bioEmplName</th>\n",
       "      <th>bioPrefAddrCity</th>\n",
       "      <th>bioPrefAddrState</th>\n",
       "      <th>bioSpId</th>\n",
       "      <th>Bday</th>\n",
       "      <th>MidName</th>\n",
       "      <th>NickName</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40483</th>\n",
       "      <td>1053951</td>\n",
       "      <td>Phillip</td>\n",
       "      <td>Frost</td>\n",
       "      <td>CEO and Chairman</td>\n",
       "      <td>OPKO Health, Inc.</td>\n",
       "      <td>Miami Beach</td>\n",
       "      <td>FL</td>\n",
       "      <td>1009702.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bioConsId bioFirstName bioLastName   bioEmplPosition  \\\n",
       "40483    1053951      Phillip       Frost  CEO and Chairman   \n",
       "\n",
       "             bioEmplName bioPrefAddrCity bioPrefAddrState    bioSpId Bday  \\\n",
       "40483  OPKO Health, Inc.     Miami Beach               FL  1009702.0  NaN   \n",
       "\n",
       "      MidName NickName  age  \n",
       "40483     NaN      NaN  NaN  "
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = df.loc[(df['bioFirstName'] == fname) & (df['bioLastName'] == lname)]\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4355: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bioConsId</th>\n",
       "      <th>bioFirstName</th>\n",
       "      <th>bioLastName</th>\n",
       "      <th>bioEmplPosition</th>\n",
       "      <th>bioEmplName</th>\n",
       "      <th>bioPrefAddrCity</th>\n",
       "      <th>bioPrefAddrState</th>\n",
       "      <th>bioSpId</th>\n",
       "      <th>Bday</th>\n",
       "      <th>MidName</th>\n",
       "      <th>NickName</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40483</th>\n",
       "      <td>1053951</td>\n",
       "      <td>Phillip</td>\n",
       "      <td>Frost</td>\n",
       "      <td>CEO and Chairman</td>\n",
       "      <td>OPKO Health, Inc.</td>\n",
       "      <td>Miami Beach</td>\n",
       "      <td>FL</td>\n",
       "      <td>1009702.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bioConsId bioFirstName bioLastName   bioEmplPosition  \\\n",
       "40483    1053951      Phillip       Frost  CEO and Chairman   \n",
       "\n",
       "             bioEmplName bioPrefAddrCity bioPrefAddrState    bioSpId Bday  \\\n",
       "40483  OPKO Health, Inc.     Miami Beach               FL  1009702.0  NaN   \n",
       "\n",
       "      MidName NickName  age  \n",
       "40483     NaN      NaN  NaN  "
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows['bioEmplName'].fillna('', inplace=True)\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['OPKO', 'Health', 'Inc']]"
      ]
     },
     "execution_count": 634,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occupations = [''.join(c for c in r if c not in string.punctuation).split() for r in rows['bioEmplName']]\n",
    "occupations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bioConsId</th>\n",
       "      <th>bioFirstName</th>\n",
       "      <th>bioLastName</th>\n",
       "      <th>bioEmplPosition</th>\n",
       "      <th>bioEmplName</th>\n",
       "      <th>bioPrefAddrCity</th>\n",
       "      <th>bioPrefAddrState</th>\n",
       "      <th>bioSpId</th>\n",
       "      <th>Bday</th>\n",
       "      <th>MidName</th>\n",
       "      <th>NickName</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40483</th>\n",
       "      <td>1053951</td>\n",
       "      <td>Phillip</td>\n",
       "      <td>Frost</td>\n",
       "      <td>CEO and Chairman</td>\n",
       "      <td>OPKO Health, Inc.</td>\n",
       "      <td>Miami Beach</td>\n",
       "      <td>FL</td>\n",
       "      <td>1009702.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bioConsId bioFirstName bioLastName   bioEmplPosition  \\\n",
       "40483    1053951      Phillip       Frost  CEO and Chairman   \n",
       "\n",
       "             bioEmplName bioPrefAddrCity bioPrefAddrState    bioSpId Bday  \\\n",
       "40483  OPKO Health, Inc.     Miami Beach               FL  1009702.0  NaN   \n",
       "\n",
       "      MidName NickName  age  \n",
       "40483     NaN      NaN  NaN  "
      ]
     },
     "execution_count": 635,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_score_arr = np.zeros(len(rows))\n",
    "for i, occ in enumerate(occupations):\n",
    "    if occ:                          # this matched person has a job\n",
    "        occ_no_common = [j for j in occ if j not in common_words]       # strips the top 100 common words\n",
    "        vec = CountVectorizer()\n",
    "        X = vec.fit_transform(occ_no_common)\n",
    "        occupation_score = vec.transform(words).toarray().sum()    # this number repesents the occupation aspect of the fit\n",
    "        occupation_score_arr[i] = occupation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occupation_score():\n",
    "    occupation_score_arr = np.zeros(len(rows))\n",
    "    for i, occ in enumerate(occupations):\n",
    "        if occ:                          # this matched person has a job\n",
    "            occ_no_common = [j for j in occ if j not in common_words]       # strips the top 100 common words\n",
    "            vec = CountVectorizer()\n",
    "            X = vec.fit_transform(occ_no_common)\n",
    "            occupation_score = vec.transform(words).toarray().sum()    # this number repesents the occupation aspect of the fit\n",
    "            occupation_score_arr[i] = occupation_score\n",
    "    return occupation_score_arr.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 638,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occupation_score_arr.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "keys = ['Colby']\n",
    "X = vec.fit_transform(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sum(vec.transform(words).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 4.])"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(a, occupation_score_arr.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make this work for multiple links and print all of them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 4.]\n",
      "[0. 4.]\n",
      "[0. 4.]\n"
     ]
    }
   ],
   "source": [
    "for link in urls:\n",
    "    r  = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    words = []\n",
    "    for paragraph in soup.find_all('p'):\n",
    "        words += paragraph.text.split()\n",
    "    \n",
    "    vec = CountVectorizer()\n",
    "    keys = ['Colby']\n",
    "    X = vec.fit_transform(keys)\n",
    "\n",
    "    a = sum(vec.transform(words).toarray())\n",
    "    b = np.append(a, get_occupation_score())\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colby': 0, 'devine': 1, 'john': 2}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.vocabulary_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['colby', 'devine', 'john']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uses count vectorizer to get a count of key words\n",
    "###### Make sure you take in account of when multiple people have the same name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The raw data passed through the classifier will have the format [fname, lname, Colby, occupation_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "keys = [fname, lname, 'Colby']\n",
    "X = vec.fit_transform(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 21, 21], dtype=int64)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(vec.transform(words).toarray(), 1) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Robinson,', 'Banks,', '&', 'Anderson']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "occupation_vec = CountVectorizer()\n",
    "occupation_array = row['bioEmplName'].str.split()\n",
    "# occupation_array = [w if w not in common_words else 'a' for w in occupation_array]\n",
    "for w in occupation_array:\n",
    "#     if not w in common_words:\n",
    "      print(w)\n",
    "      print(type(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(occupation_array.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'but' in common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215    [Robinson,, Banks,, &, Anderson]\n",
       "Name: bioEmplName, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occupation_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215    Robinson, Banks, & Anderson\n",
       "Name: bioEmplName, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = row['bioEmplName']\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Robinson', 'Banks', 'Anderson']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(c for c in a.values[0] if c not in string.punctuation).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Banks' in a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Robinson, Banks, & Anderson'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.google.com/alerts/feeds/16218955178302834825/8278055857187349425'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "m = re.findall('alerts/feeds\\S+', text)\n",
    "url = ('https://www.google.com/' + m[0]).replace('\\\"', '')\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r  = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(r.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.com/url?rct=j&sa=t&url=http://www.millburysutton.com/articles/millbury-jr-sr-high-school-honor-roll-4/&ct=ga&cd=CAIyGjQxZWUzODg3MmI2ZDRmYmE6Y29tOmVuOlVT&usg=AFQjCNFJUfO5HZt9uN0OEXWnBxlF2r4aaQ\n"
     ]
    }
   ],
   "source": [
    "# use &ct as a stopper\n",
    "\n",
    "web_lists = soup.find_all('link')[1:]\n",
    "for web in web_lists:\n",
    "    print(web['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.google.com/url?rct=j&sa=t&url=http://www.millburysutton.com/articles/millbury-jr-sr-high-school-honor-roll-4/&ct=ga&cd=CAIyGjQxZWUzODg3MmI2ZDRmYmE6Y29tOmVuOlVT&usg=AFQjCNFJUfO5HZt9uN0OEXWnBxlF2r4aaQ'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = web_lists[0]['href']\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.millburysutton.com/articles/millbury-jr-sr-high-school-honor-roll-4/']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[re.findall('url=(.*?)&', url['href'])[0] for url in web_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_soup = BeautifulSoup(requests.get(url).content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'window.googleJavaScriptRedirect=1var n={navigateTo:function(b,a,d){if(b!=a&&b.google){if(b.google.r){b.google.r=0;b.location.href=d;a.location.replace(\"about:blank\");}}else{a.location.replace(d);}}};n.navigateTo(window.parent,window,\"http://www.nydailynews.com/new-york/woman-gave-no-hints-trouble-found-butchered-park-article-1.3955035\");\\n'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_first_text_block(email_message_instance):\n",
    "    maintype = email_message_instance.get_content_maintype()\n",
    "    if maintype == 'multipart':\n",
    "        for part in email_message_instance.get_payload():\n",
    "            if part.get_content_maintype() == 'text':\n",
    "                return part.get_payload()\n",
    "    elif maintype == 'text':\n",
    "        return email_message_instance.get_payload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get_first_text_block(email_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using mail.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type, data = mail.search(None, 'ALL')\n",
    "mail_ids = data[0].decode()\n",
    "id_list = mail_ids.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_email_id = int(id_list[0])\n",
    "latest_email_id = int(id_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "typ, data = mail.fetch('4', '(RFC822)' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From : None\n",
      "\n",
      "Subject : None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for response_part in data:\n",
    "    if isinstance(response_part, tuple):\n",
    "        msg = email.message_from_string(str(response_part[1]))\n",
    "        email_subject = msg['subject']\n",
    "        email_from = msg['from']\n",
    "        print( 'From : ' + str(email_from) + '\\n')\n",
    "        print ('Subject : ' + str(email_subject) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "raw_email = data[0][1]\n",
    "email_message = email.message_from_string(str(raw_email))\n",
    "print(email_message['To'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bytes'>\n"
     ]
    }
   ],
   "source": [
    "for response_part in data:\n",
    "    if isinstance(response_part, tuple):\n",
    "        print(type(response_part[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import smtplib\n",
    "import time\n",
    "import imaplib\n",
    "import email\n",
    "def read_email_from_gmail(user, pw):\n",
    "    try:\n",
    "        mail = imaplib.IMAP4_SSL(SMTP_SERVER)\n",
    "        mail.login(user, pw)\n",
    "        mail.select('inbox')\n",
    "\n",
    "        typ, data = mail.search(None, 'ALL')\n",
    "        mail_ids = data[0]\n",
    "\n",
    "        id_list = mail_ids.split()   \n",
    "        first_email_id = int(id_list[0])\n",
    "        latest_email_id = int(id_list[-1])\n",
    "\n",
    "\n",
    "        for i in range(latest_email_id,first_email_id, -1):\n",
    "            typ, data = mail.fetch(str(i), '(RFC822)' )\n",
    "\n",
    "            for response_part in data:\n",
    "                if isinstance(response_part, tuple):\n",
    "                    msg = email.message_from_string(response_part[1])\n",
    "                    email_subject = msg['subject']\n",
    "                    email_from = msg['from']\n",
    "                    print( 'From : ' + email_from + '\\n')\n",
    "                    print ('Subject : ' + email_subject + '\\n')\n",
    "\n",
    "    except Exception as e:\n",
    "        print (e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_value must be str or None, not bytes\n"
     ]
    }
   ],
   "source": [
    "read_email_from_gmail(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
